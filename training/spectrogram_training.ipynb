{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EdALOIYWqc4H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665328869221,"user_tz":-480,"elapsed":25331,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"0de4798d-7ffc-4fda-9da2-2d0583f4f9c9"},"source":["!pip install torch\n","!pip install torchvision\n","!pip install sklearn\n","!pip install tqdm"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.2.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=86129d78795263f71ff300d92db824b4e764d395ad52b03cf8d1ab4ec03ad4c3\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built sklearn\n","Installing collected packages: sklearn\n","Successfully installed sklearn-0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"]}]},{"cell_type":"code","metadata":{"id":"8LvvwA1Lu_-Y","executionInfo":{"status":"ok","timestamp":1666072842278,"user_tz":-480,"elapsed":1322,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}}},"source":["import os\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from sklearn.metrics import confusion_matrix"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5l1ETV8ZDZ3","executionInfo":{"status":"ok","timestamp":1666072889963,"user_tz":-480,"elapsed":47688,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"e372014d-7279-4232-fa77-5066cf648ac3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"8ygdD1SwAGog","executionInfo":{"status":"ok","timestamp":1666072889963,"user_tz":-480,"elapsed":4,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}}},"source":["root_path = \"/content/drive/MyDrive/NUS/CS4243/CS4243_mini_project\"\n","data_path = os.path.join(root_path, \"spectrogram_data_split\")\n","model_root_path = os.path.join(root_path, \"models\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# helper function to display images\n","def imshow(img):\n","    npimg = img.cpu().numpy()\n","    plt.figure(figsize=(20, 20))\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))"],"metadata":{"id":"DWu_8BrYwFc6","executionInfo":{"status":"ok","timestamp":1666072895799,"user_tz":-480,"elapsed":4,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"M24J85St9Mz2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666072902090,"user_tz":-480,"elapsed":6294,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"bc2a6a19-c917-432a-d7fb-db9424d3125c"},"source":["input_size = (299, 299)\n","batch_size = 32\n","is_split = True\n","# train, validation, test\n","data_split = [0.8, 0.1, 0.1]\n","\n","# Image transformations\n","transform = transforms.Compose([\n","    transforms.Resize(input_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","if is_split:\n","    # Load data that has already been split\n","    print(\"Reading from split data...\")\n","    train_path = os.path.join(data_path, \"train\")\n","    validation_path = os.path.join(data_path, \"validation\")\n","    test_path = os.path.join(data_path, \"test\")\n","    datasets = (torchvision.datasets.ImageFolder(x, transform) for x in [train_path, validation_path, test_path])\n","else:\n","    # Load and split data\n","    print(\"Reading and splitting data...\")\n","    dataset = torchvision.datasets.ImageFolder(data_path, transform)\n","    n_data = len(dataset)\n","    n_train = int(n_data * data_split[0])\n","    n_validation = int(n_data * data_split[1])\n","    n_test = n_data - n_train - n_validation\n","    datasets = random_split(dataset, (n_train, n_validation, n_test))\n","    train_dataloader, validation_dataloader, test_dataloader = (DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2) for ds in datasets)\n","\n","train_dataloader, validation_dataloader, test_dataloader = (DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2) for ds in datasets)\n","num_train = len(train_dataloader) * batch_size\n","num_validation = len(validation_dataloader) * batch_size\n","num_test = len(test_dataloader) * batch_size\n","print(num_train, \"training\")\n","print(num_validation, \"validation\")\n","print(num_test, \"testing\")\n","print(\"Total:\", num_train + num_validation + num_test)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading from split data...\n","1312 training\n","192 validation\n","192 testing\n","Total: 1696\n"]}]},{"cell_type":"code","metadata":{"id":"wYfZ9yk6AKfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666072913492,"user_tz":-480,"elapsed":728,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"4cb0d85a-f6bb-45b9-b147-8bade27a0f9c"},"source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n","num_classes = len(next(os.walk(data_path))[1])\n","print(f\"Found {num_classes} classes\")\n","model.AuxLogits.fc = nn.Linear(768, num_classes)\n","model.fc = nn.Linear(2048, num_classes)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"output_type":"stream","name":"stdout","text":["Found 3 classes\n"]}]},{"cell_type":"code","metadata":{"id":"M5Cz7s6HgCG5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666072910383,"user_tz":-480,"elapsed":4509,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"31939e53-4f42-40e8-ff03-e29e183c854c"},"source":["model_load_path = os.path.join(model_root_path, 'inception_spectrogram_classifier_e10_lr3')\n","model.load_state_dict(torch.load(model_load_path))"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"42RibqW_-N_X"},"source":["# get some random training images\n","dataiter = iter(train_dataloader)\n","images, labels = dataiter.next()\n","\n","print(\"Image batch dimensions:\", images.shape)\n","print(\"Image label dimensions:\", labels.shape)\n","\n","out = model(images)\n","print(\"Model output dimensions:\", out.shape)\n","\n","## show images\n","imshow(torchvision.utils.make_grid(images))\n","print(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ud4lVoHEf6To","executionInfo":{"status":"ok","timestamp":1666073349376,"user_tz":-480,"elapsed":664,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}}},"source":["learning_rate = 1e-3\n","lr_decay = 0.9\n","num_epochs = 10\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zCZcwk9jZeY","executionInfo":{"status":"ok","timestamp":1666073349376,"user_tz":-480,"elapsed":3,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}}},"source":["def get_labels(logit, size):\n","    return torch.max(logit, dim=1)[1].view(size)\n","\n","def get_accuracy(logit, target, batch_size):\n","    corrects = (get_labels(logit, target.size()).data == target.data).sum()\n","    accuracy = 100.0 * corrects/batch_size\n","    return accuracy.item()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAdLiFhgeb1j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666073558795,"user_tz":-480,"elapsed":207324,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"14b098f3-2f0a-4e6c-c646-b43b4c5958bd"},"source":["model_save_path = os.path.join(model_root_path, \"inception_ensemble_spectrogram_classifier_lr3_e20_elr9\")\n","\n","for epoch in range(num_epochs):\n","\n","    train_running_loss = 0.0\n","    train_acc = 0.0\n","\n","    model = model.train()\n","\n","    # training steps\n","    pbar = tqdm(total=len(train_dataloader))\n","    for i, (images, labels) in enumerate(train_dataloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # forward + backprop + loss\n","        logit, aux_logit = model(images)\n","        loss = criterion(logit, labels)\n","        aux_loss = criterion(aux_logit, labels)\n","        loss = loss + 0.4 * aux_loss\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # update model params\n","        optimizer.step()\n","\n","        # calc training metrics\n","        train_running_loss += loss.detach().item()\n","        train_acc += get_accuracy(logit, labels, batch_size)\n","\n","        # increment progress bar\n","        pbar.update(1)\n","\n","    pbar.close()\n","    scheduler.step()\n","\n","    val_running_loss = 0.0\n","    val_acc = 0.0\n","    model.eval()\n","\n","    # validation step\n","    for j, (images, labels) in enumerate(validation_dataloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # forward step and loss, no bacckprop\n","        logit = model(images)\n","        loss = criterion(logit, labels)\n","\n","        # calc validation metrics\n","        val_running_loss += loss.detach().item()\n","        val_acc += get_accuracy(logit, labels, batch_size)\n","\n","\n","    print('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Validation Loss: %.4f | Validation Accuracy: %.2f' \\\n","          %(epoch, train_running_loss/i, train_acc/i, val_running_loss/j, val_acc/j))        \n","\n","torch.save(model.state_dict(), model_save_path)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0 | Train Loss: 1.2744 | Train Accuracy: 58.59 | Validation Loss: 1.7654 | Validation Accuracy: 48.12\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | Train Loss: 1.1883 | Train Accuracy: 61.80 | Validation Loss: 1.8622 | Validation Accuracy: 36.25\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2 | Train Loss: 1.0807 | Train Accuracy: 64.53 | Validation Loss: 1.2104 | Validation Accuracy: 51.25\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3 | Train Loss: 1.0565 | Train Accuracy: 66.72 | Validation Loss: 1.2938 | Validation Accuracy: 43.75\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4 | Train Loss: 1.1052 | Train Accuracy: 64.38 | Validation Loss: 1.3018 | Validation Accuracy: 41.88\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5 | Train Loss: 0.9130 | Train Accuracy: 69.92 | Validation Loss: 1.3573 | Validation Accuracy: 45.62\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6 | Train Loss: 0.8323 | Train Accuracy: 74.06 | Validation Loss: 1.3811 | Validation Accuracy: 44.38\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7 | Train Loss: 0.8152 | Train Accuracy: 71.48 | Validation Loss: 1.5214 | Validation Accuracy: 46.88\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8 | Train Loss: 0.8798 | Train Accuracy: 71.41 | Validation Loss: 1.3989 | Validation Accuracy: 48.12\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41/41 [00:19<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9 | Train Loss: 0.7513 | Train Accuracy: 74.61 | Validation Loss: 1.3920 | Validation Accuracy: 48.12\n"]}]},{"cell_type":"code","metadata":{"id":"v--nPmuJoRsX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666073568731,"user_tz":-480,"elapsed":1337,"user":{"displayName":"Pinxi Tan","userId":"18380449730269389662"}},"outputId":"bb089c9e-eb5c-4407-8e83-0117ea37f381"},"source":["model.eval()\n","\n","test_acc = 0\n","total_conf_table = np.zeros((3, 3))\n","\n","for i, (images, labels) in enumerate(test_dataloader):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # forward step\n","    logit = model(images)\n","    pred = get_labels(logit, labels.size())\n","    # calc validation metrics\n","    test_acc += get_accuracy(logit, labels, batch_size)\n","    pred_np = pred.cpu().detach().numpy()\n","    label_np = labels.cpu().detach().numpy()\n","    conf_table = confusion_matrix(label_np, pred_np, labels=[0, 1, 2])\n","    total_conf_table += conf_table\n","\n","print(\"Test Accuracy: %.2f\" %(test_acc/i)) \n","print(\"Confusion Table:\")\n","print(total_conf_table)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 56.88\n","Confusion Table:\n","[[24. 16. 10.]\n"," [ 2. 42. 10.]\n"," [ 5. 27. 25.]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OoWexbGp9zLB"},"execution_count":null,"outputs":[]}]}